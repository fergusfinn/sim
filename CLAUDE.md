# Development Guide

This document provides important information for developing the LLM Inference Simulator.

## Architecture Overview

This project consists of two main components:

1. **Rust Simulator Core** (`src/`) - High-performance simulation engine compiled to both native binary and WebAssembly
2. **Web UI** (`web/`) - React + TypeScript frontend that loads the WASM module

## Development Workflow

### Working on Rust Code

When you make changes to the Rust simulator (`src/`), you need to rebuild the WASM module and update the web dependencies.

**Quick rebuild command:**
```bash
cd web
npm run rebuild-wasm
```

This script does two things:
1. Runs `wasm-pack build --target web --no-default-features` to compile Rust to WASM
2. Runs `npm install` to update the local `sim` package dependency

**Why is this necessary?**

The web app depends on the WASM package via `"sim": "file:../pkg"` in `package.json`. When you rebuild with `wasm-pack`, it updates the `pkg/` directory, but npm doesn't automatically detect changes to file-based dependencies. Running `npm install` forces npm to copy the updated package to `node_modules/sim/`.

**Alternative manual steps:**
```bash
# From project root
wasm-pack build --target web --no-default-features

# Then update npm dependencies
cd web && npm install
```

### Running the Development Server

```bash
cd web
npm run dev
```

The dev server will automatically reload when you make changes to the React/TypeScript code. However, for Rust changes, you must run `npm run rebuild-wasm` first.

### Building for Production

**CLI binary:**
```bash
cargo build --release
./target/release/sim --config config.toml
```

**Web app:**
```bash
# First ensure WASM is built
wasm-pack build --target web --no-default-features

# Then build the web app
cd web
npm run build
```

The production build will be in `web/dist/`.

## Project Structure

```
sim/
├── src/                    # Rust simulator core
│   ├── main.rs             # CLI entry point
│   ├── lib.rs              # Library root
│   ├── wasm.rs             # WebAssembly bindings
│   ├── simulation/         # Main simulator logic
│   ├── scheduler/          # Scheduling policies
│   ├── compute/            # Performance calculations
│   ├── kv_cache/           # KV cache management
│   ├── request/            # Request generation
│   └── metrics/            # Performance metrics
├── web/                    # React web interface
│   ├── src/
│   │   ├── App.tsx         # Main React app
│   │   └── main.tsx        # Entry point
│   ├── package.json        # Dependencies (includes "sim": "file:../pkg")
│   └── dist/               # Production build output
├── pkg/                    # WASM build output (generated by wasm-pack)
├── config.toml             # Default simulation config
├── test_blog.toml          # Blog benchmark config
└── Cargo.toml              # Rust project configuration

```

## Common Issues

### WASM changes not appearing in web UI

**Symptom:** You made changes to Rust code, rebuilt with `wasm-pack`, but the web UI still shows old behavior.

**Solution:** Run `npm run rebuild-wasm` from the `web/` directory. The npm dependencies need to be refreshed to pick up the new WASM binary.

### CORS errors when loading WASM

**Symptom:** Browser console shows CORS or SharedArrayBuffer errors.

**Solution:** The dev server is configured with the necessary headers in `vite.config.ts`. Make sure you're running `npm run dev` and not opening the HTML file directly.

## Configuration Files

- `config.toml` - Default config (H100, Llama-3-70B, Poisson arrivals)
- `test_blog.toml` - Blog benchmark (H100 TP=2, closed-loop, 64 users)

Configuration includes:
- Hardware specs (FLOPS, bandwidth, VRAM)
- Model architecture (parameters, layers, heads)
- Scheduler settings (max tokens, policies, chunked prefill)
- Workload patterns (arrival patterns, request distributions)

## Testing

Run Rust tests:
```bash
cargo test
```

Run web linting:
```bash
cd web
npm run lint
```

## Performance Metrics

The simulator tracks:
- **TTFT**: Time to First Token (prefill latency)
- **E2E**: End-to-End latency (total request time)
- **Per-token latency**: Average decode latency per token
- **Throughput**: Tokens per second
- **Utilization**: GPU compute and memory bandwidth usage

Results include percentiles (p50, p90, p99) and means.
